# Generating Captions for the Images
## Introduction
Humans can understand an image easily but computers are far behind from humans in understanding the context by seeing an image. However, technology is evolving and various     m  methods have been proposed through which we can automatically generate captions for the image. 
## GOAL: 
 -> **input** : Image ----------- **output** : caption generate from the given image 
## Technology used:
- Data cleaning
- Nlp
- CNN
- RNN 
- Langauage Model
- Word Embedings 
- Transfer learning 
## Applications 
- Self driving cars
- Aid to the blind : We can create a product for the blind which will guide them travelling on the roads without the support of anyone else. We can do this by first converting the   scene into text and then the text to voice
- CCTV Cameras 
- Automatic Captioning can help, make Google Image Search
## Dataset 
- I used Flickr8k Dataset to train my model if we use Flickr30k Dataset then we can get even more accuracy 
- Flickr 8k Dataset is already divided into 6000 images for training and 1000 images for validation and 1000 for testing 
- link for the Data set :-> https://www.kaggle.com/shadabhussain/flickr8k
- Glove.6b.50.d used for word embeddings which is pretrained netwok containing approximately 6billion words
- link https://www.kaggle.com/watts2/glove6b50dtxt 

## Results obtained:
![img](https://github.com/Apoorv070/Image_Caption_Generator/blob/master/output.PNG)
